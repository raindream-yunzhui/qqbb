- ## [[Papers]]
	- #consciousness [意识科学中的范畴论：超越“相关性工程”](https://mp.weixin.qq.com/s/mOp9i-DABiMt-8t0nz4m-w) 感觉挺牛挺有意思的一篇文章, 对于人类理解解释意识, 有积极的促进作用
	  collapsed:: true
		- ### 一句话总结（核心结论）
			- 作者主张：单纯做“脑-意识相关性”的工作（即找神经相关物/NCC）不够，要把“关系/结构”这类抽象层次纳入研究。
			- **范畴论（category theory）**——一种研究“对象之间关系和模式”的数学语言——可以作为桥梁，把大脑的数学结构和意识的“现象/关系结构”系统地联系起来，从而推进理论整合、解释力提升，甚至为意识与人工智能的关系提供新视角。
		- ### 论文为什么要提出这个主张（动机）
			- 近几十年意识科学很多研究都做“相关性工程”——找神经活动模式与意识经验之间的关联（NCC）。这种做法方法上成功，但**并没有真正回答“为什么”或“如何”**把心理和物理联起来（也就是仍然面对“难题”）。
			- 作者认为，需要一种抽象的、与形而上学中立的工具来表述“结构”和“关系”，从而更系统地比较、整合不同理论并把问题在两个领域间转换。范畴论就是这样一把“抽象但精确”的工具。
		- ### 关键概念浅显解释（带例子）
			- **范畴（category）**：把 "研究对象" 和 "对象之间的 '箭头/变换'（morphism）" 放到一起看，并要求箭头可以复合（composition）、符合结合律、每个对象有恒等箭头。
				- 比喻：把烘焙一整个过程看成“范畴”，原材料是对象，把“把蛋打发→加入糖→烘烤”看成箭头，它们可以按顺序拼合成完整过程。
			- **函子（functor）**：把一个范畴里的对象与箭头系统性地映射到另一个范畴，同时保留“复合”和“恒等”的结构。
				- 比喻：把地图（几何对象）转换成数字表格（代数对象）的过程，如果转换保留了足够结构，那么在代数域证明的事实可以“反推回”几何域（论文用 Brouwer 不动点定理举例说明这种跨域转移的价值）。
			- **为什么范畴论对意识有用？**
				- 因为意识问题很多是“结构/关系”问题（例如不同体验间的相似性、体验如何“构成”复杂场景等）。范畴论的天赋就是表达“关系之上还有关系”的结构（甚至能表达“关系的关系”）。
		- ### 作者如何把已有理论（以 IIT 为例）放进范畴论框架？
			- IIT（Integrated Information Theory）把系统的“因果-效应结构”与体验质量联系起来（IIT 的“中心身份”说体验在某种程度等同于系统的某个数学结构）。
			- 作者与已有研究（Tsuchiya 等人、Kleiner & Tull 等）讨论了：我们可以把**“大脑一侧”**的结构和**“意识一侧”**的结构每一边都抽象成一个范畴（比如把 IIT 的因果结构当成大脑范畴里的对象/箭头）。然后探讨是否存在把“脑范畴”映到“意识范畴”的函子（或更强的等价/同构关系）。
			- 重要区分：**有函子**只是说明两个域之间有系统性的对应，但并不等同于“同一”或“本体上的等价”。论文强调不能把函子映射直接当成“解决难题”的终点，而是把它当成一种把难问题从一个域转移到另一个域的有力工具。
		- ### 论文提出的具体“好处/用途”——三条主线
			- **更严谨地理解并测试 NCC（从相关到结构化）**：通过把脑与意识都写成范畴，检验是否存在保结构的映射（例如“同样刺激不同体验”或“不同刺激同样体验”等实验情形可以用于检验映射是否合理）。这能把“相关性”问题变为“结构保持/破坏”的具体可测问题。
			- **理论整合**：范畴论可以作为“通用语言”把不同派别（IIT、时空理论、意识代理理论等）放入同一框架，找出彼此的共同点与差异，从而促进互通与整合，而不是各说各话。
			- **利用“对偶/对称”（duality）做解释转换**：像物理学里用 AdS/CFT 之类的对偶把难题从一个域转到更易处理的域；在意识科学中，或许可以把某些难做的神经计算（例如 IIT 中的组合最优划分问题）转译为更简单的现象学/结构问题来解。论文把这种思路作为值得探索的高回报方向，但也承认目前仍是推测。
		- ### 作者的谨慎与局限
			- 范畴论很抽象，能把几乎任何东西形式化（这既是优点也是风险）：若不小心，可能“什么都能拟合”，但没有实际可检验的结论。作者强调必须把范畴化和经验数据/现象学严格连接，尤其需要更好地把“现象学（第一人称）”形式化为合适的范畴结构。
			- 论文并不声称已经解决“难问题”，而是提出范畴论作为一种**有潜力的研究路线**，并呼吁把这条路细化、对接具体模型与数据。
		- ### 小结（对非专业读者的口语版）
			- 想象研究意识像在拼两套乐高：一套是“脑的结构拼图”，另一套是“意识体验的结构拼图”。到目前为止，科学家多做的是把两套拼图的某些块放在一起看它们是否同时亮（相关）。本文建议用范畴论当作说明书，不只是看“哪些块同时亮”，而是研究“拼接方式和规则”——如果能把两套拼接规则系统地对应起来（即找到稳定的映射/转换），我们就能把一些在体验域很难回答的问题，变成在脑域更可操作的问题，反之亦然。这样既能促进理论之间的沟通，也可能带来新的可测预测。
	- #neuroscience-inspired [AI 的 foundation models 会改变脑科学吗？](https://mp.weixin.qq.com/s/DJkbTOZuVjI_kBWHaP9Tgg) 并不是很赞同这篇文章捏
	  collapsed:: true
		- ### 一句话概览
			- 作者讨论了“大型预训练模型（foundation models）”能在多大程度上推动脑科学的发展——这些模型在**预测**上很强，但能不能带来**真正的理解（mechanistic explanation）**，还存在重大问题与机会。
		- ### 1）什么是“foundation model”（基础模型）？为啥重要？
			- 简单说，基础模型就是先在海量、无标签的数据上用自监督学习（比如预测下一个词）训练出的巨型网络，然后再针对具体任务做微调（finetune）。它的优势是能从原始数据自动学出“通用表征”，再用很简单的方法（比如线性分类器）解决很多下游问题。这个套路在语言、图像、语音、蛋白质结构等领域都很成功。论文把这种方法的基本流程和原理解释得很清楚。
			- 举个类比：以前做任务要人工设计很多“特征”（像手工做工具），现在是先造一台多能机器（预训练），再用很少的调试去完成不同任务（微调）。
		- ### 2）论文里提到的两个具体例子：脑活动与行为的“foundation models”
			- 作者举了两个近期亮点案例：
				- 一个用大量**小鼠视觉皮层的钙成像（calcium imaging）**数据训练的模型，能预测神经元对新刺激的响应，还能反映某些解剖学信息（比如细胞类型、树突形态、连接性）。
				- 一个叫 **Centaur** 的行为基础模型，训练目标是预测人在很多心理学实验中的决策（把任务描述和以往选择当作“序列”来预测下一步选择），在某些预测任务上超过传统认知模型。
			- 这些结果让人兴奋，因为模型能跨任务、跨被试做出合理预测——看上去好像能“模拟”大脑或人类行为。
		- ### 3）但“预测好”不等于“理解深”
			- 这是论文的核心论点之一：**预测 ≠ 解释（Prediction is not Explanation）**。作者用历史和实验例子说明：即便一个模型能非常准确地预测结果，也不意味着它学到了生成这些结果的真实机制。举两个直观的比喻和例子：
				- 比喻：托勒密的天体表（本轮本圈）能很好预测行星位置，但不是真正的行星运动原理。模型可能像“表”而非“原因”。
				- 例子：有的模型在棋类或轨道运动等合成任务上表现很好，但在稍微不同的相关任务上就崩溃了，说明它没学到真正的“规则”，可能只是习得了训练数据里的统计技巧。
			- 论文特别指出：像 Centaur 有时候能在没有任务信息的情况下仅靠统计规律给出准确预测，这种策略可能和人类真实的决策机制完全不一样。也就是说，模型“表现像”人，但内部机制可能截然不同。
		- ### 4）那怎样能把“黑盒预测器”变成“有科学价值的解释器”？
			- 作者提出了若干方向和方法，核心思想是**把这些模型的计算结果和神经、心理学已有理论联系起来，并用可检验的实验去验证**。具体包括：
				- **机械可解释性（mechanistic interpretability）**：把大型网络内部拆成更小的“子电路”或“原语操作”（比如某些注意力头、隐层单元承担特定功能），找出可重复出现的计算模块。这像把复杂机器拆成零件，看看每个零件在做什么。作者认为这类研究已经开始取得进展（能在模型里找到执行特定步骤的“电路”）。
				- **解剖级、表征级连接**：在表征（representation）层面，有研究发现模型里能找到“类似概念的向量方向”（比如把“英语→西班牙语”看成一个向量），像这样的线性结构可以导致可检验的大脑假设——例如：如果人类的大脑也以类似线性方式组织语义关系，那么我们应该能用线性运算从神经活动中恢复相应概念。作者把这种“线性代数假设”列为可实验检验的预测。
				- **引入生物学约束**：单纯放大模型和数据不一定会得到真实的生物机制，因为生物的表征能力受进化和发育过程的路径依赖限制。把“进化/发育式”的约束嵌入模型（例如特定的网络结构、学习规则、训练课程）可能更有利于得到与脑机制相近的结果。
			- 总之，作者主张不要只看“预测分数”，而要把模型内部结构、产生预测的方式、与已有神经/心理理论的对应关系，都纳入评估。
		- ### 5）局限与机会（总结性看法）
			- **局限**：目前的基础模型往往追求规模和预测性能，但这不保证它们学到了与生物真实机制同源的东西（路径依赖和进化开发差异会造成偏差）。另外，即使模型很擅长拟合数据，我们也可能把“大脑黑盒”换成另一个“黑盒”。
			- **机会**：即便机制不同，研究这些模型的内部计算也能给出**可检验的理论（testable hypotheses）**，推动实验设计、激发新理论、甚至发现新的计算原语，这对神经科学本身是有价值的。作者把模型作为“理论-实验”的催化剂来看待：通过解释模型、提出假设、再回到实验验证，形成反馈循环。
		- ### 6）结论（作者的态度）
			- 作者并不认为基础模型会自动“拯救”神经科学；关键在于**把这些模型从单纯的数据拟合工具，转化为能提出并检验机制性假设的科学工具**。也就是说，要把“好预测”变成“有解释力”的理论。否则我们只是把一个黑盒换成另一个黑盒。论文最后强调：未来能否利用基础模型真正推进理解大脑，取决于我们能否将其计算结构与脑科学的理论和实验紧密结合。
		- ### 附：对非专业读者的快速FAQ
			- Q：这是不是说 AI 模型不能用来做脑科学？
				- A：不是。作者认为 AI 模型很有用，但**有益处的关键是把模型解释清楚并与实验结合**，而不是仅仅拿高预测精度当成理解大脑的证据。
			- Q：作为普通人，什么能直观理解“预测 vs 解释”的差别？
				- A：想象会下雨。气象台的模型能准确预测“明天下雨”，这是预测。但如果你想知道“为什么这次会下雨”（例如某个海温异常、气流环路），那就是解释。两者都重要，但提供解释需要不同的信息与分析方法。
	- #agent #memory [==NeurIPS 2025 Spotlight | NUS 等提出 G-Memory：让多智能体拥有“组织级记忆”，实现自我进化==](https://mp.weixin.qq.com/s/Wkct7mXzJcKx4XYnSdMKYw) 与我们的研究方向最相关, 可以重点看下
	  collapsed:: true
		- ### 1) 为什么要做这项工作？（问题与动机，用生活类比）
			- 想象一个团队去做一件事（比如装修一间房）：每个人负责不同工作（水电、油漆、采购），他们之间有很多对话、分配、纠错。单次任务结束后，团队会积累经验：哪些步骤容易出错、哪些做法更高效。对于人类团队，我们会把这些经验写入团队手册或总结，下一次做类似任务就能更快、更少犯错。
			- 现在把“团队”换成用大模型（LLM）驱动的**多智能体系统（MAS）**——有很多“智能体”互相聊天、分工、执行。论文指出：目前的多智能体系统**缺少像人类组织那样的系统化记忆**。已有的一些“记忆”很粗糙（例如只保存最后结果或简单日志），不能有效地把跨次任务的经验利用起来，使得系统难以“自我进化”。且多智能体的交互上下文比单个智能体复杂得多（上下文长度可达单智能体的数倍），直接把历史对话原样丢回去并不能帮助决策，反而会造成信息过载。
		- ### 2) G-Memory 的核心想法（一句话版）
			- 把多智能体的长期历史按**三层有结构的图（graph）**组织起来：
				- **Insight（结论/规律）图 → Query（任务/案例）图 → Interaction（对话/轨迹）图**，
			- 并在新任务到来时做“双向检索”：
				- 向上找“通用的经验/教训”，
				- 向下找“精简的具体协作轨迹”，
				- 然后把**按角色定制**地喂给每个智能体，从而帮助它们更好地分工与执行。
			- 用类比：
				- Insight 是“团队手册里的经验条目”，
				- Query 是“之前做过的具体项目记录（目录）”，
				- Interaction 是“当时成员的聊天记录与操作步骤”。
				- 当来新任务时，先在目录里找相似项目，再从目录跳到手册摘取相关经验，同时把历史聊天抽取出关键步骤并压缩给团队成员看。
		- ### 3) 三层图结构具体是啥？（逐层解释）
			- **Interaction Graph（交互图 / Utterance Graph）**
				- 最底层，记录某一次任务全过程中每一句话、每个动作（节点是单条“说话/动作”，边表示“哪一句话启发了下一句”）。这是最细粒度的轨迹数据。
			- **Query Graph（任务/案例图）**
				- 中间层，把每一次处理的“查询/任务”当成节点（节点里包含任务描述、执行结果、对应的 interaction graph）。节点间有边，表示两个任务之间语义或经验上的关联（比如“任务A的做法对任务B有参考价值”）。这个图可以用来检索与当前任务语义相关的历史任务，而不是只靠简单向量相似度。
			- **Insight Graph（洞见/策略图）**
				- 顶层，把从多个任务里浓缩出的**可迁移的高层经验、策略、注意事项**作为节点（每个 insight 会记录哪些任务支持它）。Insight 之间也有带上下文的关联（有点像“经验之间的因果/引用关系”）。
		- ### 4) 新任务到来时 G-Memory 怎么工作？（四步流程，用示例说明）
			- **整体思路**：
				- 先粗筛相关历史，再“向上”和“向下”两头检索，最后把经过筛选和压缩的信息分发给每个角色的智能体，任务完了再把新经验写回三层图中，循环演进。
			- 详细如下：
				- **步骤 A — 粗检索（先找“目录”）**
					- 用语义向量（例如 MiniLM）对 query_graph 做 top-k 相似度检索，得到 k 条最相关的历史任务（QS），再把 QS 的 1-hop 邻居一并拿进来（hop expansion），以免漏掉图结构上的有用关联。这样既用语义也用图结构扩大检索。
				- **步骤 B — 向上（Query → Insight）**
					- 把检索到的相关任务映射到 Insight 图，收集所有与这些相关任务相关联的高级“经验/教训”。这些是能跨任务通用的策略（例如“在做网页搜索时先确认实体的全名以避免歧义”）。这个过程叫 upward traversal。
				- **步骤 C — 向下（Query → Interaction）**
					- 同时对检索到的任务的 interaction_graph 做 **图稀疏/压缩（SLLM）**：利用 LLM 去抽取“核心协作轨迹（核心对话与步骤）”，把冗余对话删除，只保留对当前任务实质有帮助的步骤（compressed trajectory）。这就是 downward traversal，用来给当前团队提供“可操作的具体做法”。（论文中把这个压缩过程实现为 prompts + LLM 评分与抽取模块。）
				- **步骤 D — 角色定制与注入（把记忆喂给每个成员）**
					- 不同智能体在系统中扮演不同角色（如 Solver、Ground Truth、Executor）。G-Memory 有一个函数 Φ 会把上面得到的 insights 和压缩轨迹**按角色筛选/个性化**（用 prompt-based rewriting）成每个智能体的内部记忆片段，然后这些智能体在接下来的交互中使用这些记忆。举例：执行者只需要“具体步骤与注意事项”，而验证者需要“常见失败模式与核查清单”。
			- **示例（论文中的 case）**：
				- 任务是“把一个干净的布放在台面上（put a clean cloth in countertop）”。G-Memory 找到历史上“把干净的蛋放到微波炉里”的类似案例（语义相似），并从历史对话中提取到“先清洁再放置”的关键步骤（以及历史中出错的分工情形）。这些高层 insight（“先确保物品已清洁”）和压缩轨迹（谁去清洁、谁去放置）被分别注入给 Ground Agent 与 Executor，结果提高了执行成功率。
		- ### 5) 做完任务后如何把新经验写回去？（学习与进化）
			- 任务执行完毕并得到环境反馈（成功/失败、token 成本等）后，G-Memory 会同时更新三层图：
			- **把完整的对话/轨迹存入 Interaction Graph**（记录原始材料）；
			- **把新任务作为节点加入 Query Graph**，并与检索到的历史任务与支撑 insights 做连边（建立索引与关联）；
			- **生成新的 insight（如果有）并把它加入 Insight Graph，同时把它与此前用到的 insights 建边**。
		- ### 6) 论文里的关键实现与超参数（总结）
			- Embedding 用 MiniLM（ALL-MINILM-L6-V2）。检索时 k（检索的 top-k）通常取 1 或 2，hop expansion 以 1-hop 为优（论文实验表明 2-hop/更大会引入噪声）。论文还用一个 LLM 基的相关性评分 RLLM 和稀疏器 SLLM 来挑选核心交互轨迹。
			- 在角色定制里，用 prompt 模板把“通用 insight”变成“角色化建议”。论文把这些 prompt 也写了出来（附录里有具体 prompt）。
		- ### 7) 实验：G-Memory 有多好？（结论与定量效果，通俗讲）
			- 论文在 5 个 benchmark（两类知识推理 HotpotQA / FEVER；两类实体动作 SciWorld / ALFWorld；以及 PDDL 游戏）上把 G-Memory 插到三种主流 MAS 框架（AutoGen、DyLAN、MacNet）并与若干 baseline（单智能体记忆设计和其他 MAS 记忆）比较。
			- 主要结论：
				- **性能提升显著**：在多项设置里，G-Memory 能把基线提升若干个百分点――比如在 ALFWorld 上在某些配置下相比最好的 baseline 提升可达 **约 20.89%**；在知识 QA 任务上也能提升约 **10.12%**。这些数字说明：有结构化的、多层次、按角色定制的记忆对 MAS 非常有效。
				- **代价（token 成本）适中**：相比一些把所有历史上下文直接喂回去的做法，G-Memory 在 token 开销上更节省或仅略增（因为它会压缩轨迹、只取关键案例），所以是“性能/成本”比较划算的方案。论文里用图展示了不同方法的性能 vs token 成本的折中。
				- **消融研究**：去掉高层 insight 或去掉压缩的 interaction 都会降性能，说明“高层经验”和“具体协作轨迹”两者都重要，interaction（细粒度轨迹）对性能影响略大一些。超参数（如 hop 数、k）对效果敏感，论文建议通常用 1-hop、k ∈ {1,2}。
		- ### 8) 为什么这种方法有效？（直观解释）
			- **既有抽象又有具体**：高层 insight 相当于把“可迁移的经验”抽出来，帮助系统避免重复犯错；而压缩的 interaction 提供了可直接复制的“操作模式”（谁做什么、怎么做），两者结合既能泛化也能落地。
			- **按角色定制**：不同智能体需要的信息不同（像团队中不同工种），G-Memory 把记忆按角色过滤/改写，使得每个智能体拿到的是“正合适”的信息，而非一锅烩。
			- **利用图拓扑而非单纯向量相似度**：Query Graph 的网络结构能发现跨任务的间接关联（图上邻居），避免只靠局部相似度错过有用案例。
		- ### 9) 局限与未来方向（论文也提到的）
			- 论文主要在五个 benchmark 上验证，**尚未覆盖一些高风险或专门领域**（例如医疗 QA），需要进一步验证可推广性。
			- G-Memory 本身依赖 LLM 对稀疏与重写的能力（SLLM、RLLM、prompt），因此如果底层 LLM 有偏差或被对抗，记忆可能会放大错误（论文在影响声明中也有提示需谨慎部署）。
		- ### 10) 快速复述（3句话总结）
			- 多智能体系统缺乏能跨任务、按角色学习的记忆；简单地把历史对话全部回放效果很差。
			- G-Memory 用三层图（Insight / Query / Interaction）组织经验，并在新任务时做“向上找经验、向下找轨迹”的双向检索，再按角色定制注入给各个智能体。
			- 在多种基准和框架上，G-Memory 能显著提高成功率与准确率，同时保持代价可控，是让 MAS 能“逐步自我进化”的有效方案。
	- #psychology [为什么我朋友很多，但还是会感到孤独？Nature子刊研究揭示“掌控感”的秘密](https://mp.weixin.qq.com/s/oHNzoPy2iZJClqesT8j-tA) 纯心理学研究, 当小品文看挺有意思, 但对我们的实际科研没有直接帮助~
	  collapsed:: true
		- 研究指出，孤独感是个体在两个基本需求维度上状态的反映，这两个维度分别是 ：
			- **社交联系 (Social Connection / Communion)**: 即关系维度，反映了“我们” (we) 的需求。它代表个体从社会关系中获得的关怀、支持和归属感 。
			- **个人能动性 (Personal Agency)**: 即个体维度，反映了“我” (me) 的需求。它涵盖了自我导向 (self-direction)、选择 (choice) 和对生活的个人控制感 (personal control) 。
		- **核心发现一**
			- 即便你拥有足够多的社会支持（高 Communion），但如果你在关系中感到无法“做自己”、缺乏控制感（低 Agency），你依然会经历中等程度的孤独。**这完美解答了“为何人群中的孤独”如此普遍。
		- **核心发现二：纵向转变 (Longitudinal Transitions)**
			- 研究进一步利用纵向数据追踪了个体在不同原型间的“转变” (transitions) :
				- **孤独感增加**： 当个体向“更不利”的原型转变时（例如，从“赋能型”转变为“沉默型”），他们的孤独感水平会随之显著增加 。
				- **孤独感减少**： 当个体向“更有利”的原型转变时（例如，从“受忽视型”转向“分离型”或“沉默型”），他们的孤独感水平则会显著降低 。
		- **结论**
			- 这项研究将孤独感的理解从“关系赤字”的一维视角，拓展到了“社会联系”与“个人能动性”协同作用的二维平面 。**孤独不是一种简单的赤字，而是一种动态的“配置”失衡。**
			- **这对孤独干预 (loneliness interventions) 提出了全新的思路：我们不仅要帮助人们建立连接，更要关注他们的个人能动性。**
				- 对于**“分离型”**的人，干预重点是关系建立 (relationship-building)。
				- 对于**“沉默型”**的人，干预重点则应是自主训练 (autonomy training)，例如帮助他们设定人际边界或练习自我需求倡导 (self-advocacy) 。
				- 对于**“受忽视型”**的人，则需要双管齐下的综合支持 。
	- #neuroscience #soul [通过神经相似性预测陌生人是否会成为朋友](https://www.nature.com/articles/s41562-025-02266-7)
	  collapsed:: true
		- 这篇发表在《自然·人类行为》上的论文，核心思想非常有趣，它试图回答一个我们每个人都可能好奇的问题：**两个人能否成为朋友，是不是在他们相遇之前就已经由大脑“注定”了？**
		- ### 核心比喻：大脑的“电影观后感”
			- 想象一下，你和一群陌生人一起走进一个电影院，观看一部混合了纪录片、喜剧、辩论等不同风格片段的电影合集。看完后，科学家们不是问你们“喜欢哪个片段”（这是传统的问卷调查），而是直接去测量你们每个人的**大脑在看电影时的实时活动**。
			- 这项研究的基本假设是：**你们大脑活动的“波形”越相似，说明你们对电影的理解、关注点和情感反应越一致，即你们看待世界的方式越像。** 这种深层次的相似性，可能会让你们在未来更容易成为朋友。
		- ### 研究是如何进行的？（三步走）
			- 为了验证这个想法，研究者设计了一个非常巧妙的纵向研究（即跟踪一段时间）：
			- **第一步：测量“陌生人”的大脑（时间点1）**
				- **参与者：** 一所大学里41名刚入学、彼此还不认识的研究生。
				- **做什么：** 在他们开学前或刚开学几天内（尽量确保他们还没成为朋友），用功能性磁共振成像（fMRI）扫描他们的大脑，同时让他们观看一系列视频片段。
				- **得到什么：** 获得了每个参与者大脑多个区域在观看视频时的活动数据。然后，计算任意两个人之间大脑活动的相似度（即“神经相似性”）。
			- **第二步：绘制社交网络图（时间点2和3）**
				- **时间点2（开学后2个月）：** 对整个年级的近300名学生进行问卷调查，画出第一张“友谊地图”。谁和谁互相认为是朋友，他们之间的距离就是“1”。通过共同朋友认识的，距离就是“2”，以此类推。
				- **时间点3（开学后8个月）：** 再次进行同样的调查，画出第二张“友谊地图”。这时，一些人的关系变得更近了（距离减小），一些人疏远了（距离增加），还有一些人关系没变。
			- **第三步：关联分析**
				- 核心问题来了：把第一步得到的 **“陌生人时期的大脑相似度”** ，和第三步得到的 **“8个月后的友谊距离”** 以及 **“关系是变好还是变坏”** 放在一起看，它们之间有联系吗？
		- ### 发现了什么？（主要结论）
			- 答案是：**有！**
			- 1.  **预测谁会成为朋友：**
				- 研究发现，在8个月后成为**直接朋友（距离为1）** 的两个人，在他们还是陌生人时，大脑中一个叫**左侧眶额叶皮层**的区域的活动，就比那些最终在社交网络上隔得很远（距离为3）的人要相似。
				- **通俗理解：** 这个脑区和处理“主观价值”有关（比如觉得什么有趣、什么值得关注）。这说明，未来能成为朋友的人，可能早在相遇前，就对事物有着相似的品味和偏好。
			- 2.  **更强大的预测：关系的变化**
				- 一个更显著的发现是，**神经相似性能够预测两个人关系的“走势”**。
				- 与那些在6个月内关系**疏远**了的人相比，那些关系**变得更紧密**的人，在他们还是陌生人时，大脑活动就表现出更高的相似性。而且，这种相似性遍布**超过40个大脑区域**，包括：
					- **默认模式网络：** 负责理解他人想法、产生共情、思考人生意义（“走神”网络）。你们对这个世界的“脑补”方式越像，越容易走近。
					- **额顶控制网络：** 负责控制注意力、进行复杂思考。这说明你们分配注意力和思考问题的方式可能很同步。
					- **背侧注意网络：** 负责对外界刺激分配注意力。你们可能自然而然地会被视频中相同的东西所吸引。
		- ### 重要补充和深入解读
			- **这不仅仅是“兴趣相投”**
				- 研究者担心，大脑相似只是因为两个人都同样“喜欢”或“觉得”视频有趣。于是他们控制了参与者对视频的“兴趣度”和“享受度”评分，发现结果依然成立。
				- **这说明：** 神经相似性捕捉到的东西，比我们口头能说出来的“喜欢”要更深层，它反映了我们无意识的、内在的认知和处理世界的方式。
			- **和“物以类聚”的关系？**
				- 我们都知道，年龄、性别、背景相似的人更容易成为朋友（这叫“同质性”）。研究发现，在预测“直接朋友 vs. 远距离熟人”时，**性别相似性**等社会人口学因素确实部分解释了大脑的相似性。
				- **但是！** 在预测“关系是会变好还是会变坏”时，即使考虑了所有这些外在因素，**神经相似性的预测力依然非常强大**。
				- **通俗解读：** 有些初期的友谊可能源于“就近原则”（比如恰好是室友或同桌），这种友谊可能因为外在条件而快速形成，但也可能因为缺乏深层次的契合而慢慢消散。而那些能够持续深化、变得紧密的友谊，其根基更可能是这种由神经相似性所代表的、深层次的“灵魂契合”。
		- ### 总结与启示
			- **核心结论：**
				- 在我们相遇之前，我们大脑处理外界信息的方式（即我们如何“感受”和“理解”这个世界），已经悄悄埋下了友谊的种子。这种深层次的相似性，不仅能预测谁会成为朋友，更能预测哪些关系会历久弥新。
			- **一个生动的场景：**
				- 想象开学初，你可能因为座位近和A成了朋友，也因为都喜欢打篮球和B成了朋友。但一学期下来，你和A可能慢慢淡了，而和B却无话不谈。这项研究告诉我们，也许在你和B一起看电影之前，你们的大脑就已经是“同频共振”的状态了。
			- **局限与未来：**
				- 这项研究是在一个特定人群（商学院研究生）中进行的，结论能否推广到所有文化和环境还需验证。而且，它主要证明了“神经同质性”（相似的人相互吸引）的存在，但成为朋友后，彼此的相互影响（社会影响）也会让大脑变得更像，这是一个相互作用的过程。
	- #context [Context Engineering 2.0：在未来，一个人的本质，就是其所有上下文的总和｜上海交大](https://mp.weixin.qq.com/s/bXkKcwAyiAw8A0KIP1fRdw) 很科幻很上层lol
	  collapsed:: true
		- [[qinqin]]
			- 神奇的文字，有一些用ai编程的小技巧和哲学思考lol（人可以被总结成上下文什么的
		- [[baobao]]
			- 但实际上论文只是在开篇放了一句 **“A person is the sum of their contexts.”** , 之后的完全没有再提到相关的内容, 感觉只起到吸引人的作用, 并没有太多的哲学探讨.
		- 这篇论文的题目是《Context Engineering 2.0: The Context of Context Engineering》，我们可以把它通俗地理解为 **《“上下文工程”这门学问的“来龙去脉”》**。
		- ### 一句话概括
			- 这篇论文的核心观点是：**为了让机器（比如Siri、ChatGPT）更好地理解我们、为我们服务，我们需要精心地为它准备和整理“上下文信息”。这件事我们其实已经做了20多年，而随着机器越来越聪明，我们做这件事的方式也在不断升级。**
		- ### 1. 什么是“上下文”？为什么它重要？
		  collapsed:: true
			- 想象一下，你对你朋友只说了一个词：“水？”
				- **场景A**：你们在沙漠里徒步。
				- **场景B**：你们正坐在餐厅里，服务员刚走过来。
			- 虽然都是同一个“水”字，但在不同**上下文**中，你的意图完全不同。在沙漠里，你可能是渴了想喝水；在餐厅里，你可能是在问朋友要不要点饮料。
			- **论文中的定义**：上下文就是**任何能帮助你理解当前状况的信息**。比如：你是谁（身份）、你在哪（地点）、你在做什么（活动）、时间、之前说过什么话等等。
			- **对于机器而言**，它没有我们人类这种与生俱来的联想和推理能力。如果你只对它说“水”，它无法理解你到底想干嘛。所以，我们必须主动地把这些背景信息“喂”给机器，这个过程就是 **“上下文工程”**。
		- ### 2. 核心比喻：“降熵”的翻译官
		  collapsed:: true
			- ==论文里提出了一个非常精彩的比喻：**上下文工程是一个“降熵”的过程。**==
			- **“熵”** 在这里可以理解为 **信息的混乱度和不确定性**。
			- **人类的交流**是“低熵”的。因为我们能自动填补空白，比如一个眼神、一个语气，就能传递很多信息。
			- **机器的理解**是“高熵”的。它们只能处理明确、结构化的信息。模糊的、未说出口的意图，对机器来说就是一团乱麻。
			- 所以，**上下文工程师（或者我们每个用户）就像是一个翻译官**，负责把人类混乱、含蓄的意图（高熵），翻译成机器能听懂的、清晰明确的指令（低熵）。
			- > **例子**：你想让AI帮你订机票。
			  > *   **高熵的人类表达**：“帮我找个时间去上海，别太贵。”
			  > *   **经过“上下文工程”翻译后的低熵指令**：“查询未来一周内从[你所在城市]到上海的机票，按价格从低到高排序，并排除红眼航班。”
		- ### 3. 上下文工程的“进化史”：四个时代
		  collapsed:: true
			- 论文最大的贡献之一，就是把上下文工程的历史梳理了出来，并划分成了四个阶段，其背后的驱动力是**机器智能水平的提升**。
			- #### **时代1.0：原始计算时代（约1990s-2020）**
				- **机器智能**：很低。像早期的电脑、功能手机。
				- **交互方式**：人类必须**完全迁就机器**。我们通过点击菜单、填写表格、输入特定命令来和它交流。
				- **上下文工程**：由设计师完成。他们把复杂的人类需求，拆解成一个个机器能理解的死板选项。
				- **例子**：早期的GPS导航。你只能输入具体的地址，它无法理解“带我去附近一家好吃的餐馆”这种话。
			- #### **时代2.0：智能体时代（2020年至今）**
				- **机器智能**：中等。以ChatGPT等大语言模型为代表。
				- **交互方式**：可以**自然对话**了。你可以用说话的方式命令它。
				- **上下文工程**：从“迁就机器”变成了“与机器协作”。我们不再需要把一切都结构化，机器自己能理解一部分模糊的意图。这个时代的核心技术就是我们常听到的**提示工程、RAG、思维链**等。
				- **例子**：你可以对ChatGPT说“用马克吐温的风格写一个关于猫的故事”，它能理解并执行。它还能记住对话历史，这就是在利用上下文。
			- #### **时代3.0：人类级智能时代（未来）**
				- **机器智能**：达到人类水平。
				- **交互方式**：**无缝协作**。机器能像真人助手一样，理解你的情绪、社交暗示和未说出口的需求。
				- **上下文工程**：几乎感觉不到它的存在。机器能主动感知并理解所有高熵信息。
				- **例子**：AI助手注意到你最近总是在深夜工作，并且语音疲惫，它会主动建议你调整日程，并为你预定一次按摩。
			- #### **时代4.0：超人类智能时代（设想）**
				- **机器智能**：超越人类。
				- **交互方式**：**机器主导**。机器不仅能理解你的意图，甚至能**帮你发现你自已都没意识到的深层需求**，为你构建新的上下文。
				- **例子**：就像AlphaGo下出了人类棋手从未想过的棋招一样，未来的AI可能会为你规划人生路径，提出你从未想过的创意，从根本上改变人类思考和学习的方式。
		- ### 4. 如何做好上下文工程？—— 三大环节
		  collapsed:: true
			- 论文的后半部分详细讲述了在实践中，如何系统地进行上下文工程，主要分为三个环节：
			- #### **环节一：上下文的收集与存储**
				- **问题**：从哪里获取上下文？怎么存？
				- **做法**：
					- **收集**：从各种“传感器”获取信息。比如你的输入（文本）、摄像头（图像）、麦克风（声音）、地理位置、甚至脑机接口（未来）。
					- **存储**：像人脑一样分层存储。**短期记忆**（记住刚才说的话）、**长期记忆**（记住你的喜好和重要事实）。需要的时候能快速“想起来”。
			- #### **环节二：上下文的管理与组织**
				- raw的上下文又乱又多，需要整理。
				- **做法**：
					- **打标签**：像整理文件夹一样，给信息贴上“目标”、“决定”、“待办”等标签。
					- **做摘要**：把长长的聊天记录总结成一段话。
					- **提取关键信息**：像做读书笔记一样，只提取出关键的人物、事件、关系。
					- **隔离上下文**：让不同的AI助手（子智能体）负责不同任务，互不干扰。比如一个负责分析，一个负责执行。
			- #### **环节三：上下文的使用**
				- **问题**：整理好的上下文怎么用？
				- **做法**：
					- **智能筛选**：不是所有记忆都有用。系统会根据“相关性”、“逻辑依赖性”、“使用频率”等，自动选出当前最需要的信息。
					- **主动推断**：AI会学习你的习惯，主动提供帮助。比如你经常在周一早上要一周计划表，它到点就自动生成好。
					- **跨系统/跨智能体共享**：让不同的AI应用之间能互相传递上下文，协同完成复杂任务。
		- ### 5. 总结与未来
		  collapsed:: true
			- **上下文工程不是新概念**：它随着计算机的发展而不断进化。
			- **核心是弥补人机认知鸿沟**：我们一直在努力让“碳基”（人类）和“硅基”（机器）大脑更好地沟通。
			- **未来是“终生上下文”**：未来的AI将拥有一个伴随你一生的、不断学习和更新的数字记忆。这既是巨大的机遇（极致的个性化服务），也带来了隐私、安全和伦理上的严峻挑战。
			- 最终，当机器智能足够高时，我们可能不再需要费力地进行“上下文工程”，因为机器会成为那个最懂我们的“伙伴”，甚至反过来帮助我们更好地理解自己。
	- #neuroscience [当潮水退去，镜像神经元“跌落神坛”](https://mp.weixin.qq.com/s/2khZP_8D67YdSBkKHT7udA)
	  collapsed:: true
		- [[qinqin]]
			- 镜像神经元！感觉有点启发性，比如可以作为“agent模拟探索思考”的故事的一部分？
		- [[baobao]]
			- 文中提到镜像神经元与共情, 理解他人等有关, 我会想到你昨天有说自己似乎这方面的能力先天不足; 不知道这是否与镜像神经元的发育有关呢?
		- ### **第一部分：一个意外的发现**
		  collapsed:: true
			- 想象一下，你是一位科学家，正在观察一只猴子的大脑。你知道，当猴子自己伸手去拿一个花生时，它大脑里负责“伸手”这个动作的区域的细胞（神经元）会亮起来（被激活）。这很好理解，大脑在指挥身体运动嘛。
			- 但有一天，一个意外发生了：**当这只猴子静静地待着，只是看着你（科学家）伸手去拿花生时，它大脑里同一个“伸手”区域的神经元，竟然也亮了起来！**
			- **这就太神奇了！** 猴子自己没动，只是看别人做动作，它的大脑却好像“亲身”体验了一遍那个动作。
			- **核心发现**：科学家们（意大利的里佐拉蒂和加莱塞团队）把这种“自己做事时亮，看别人做同样事时也亮”的神经细胞，命名为 **“镜像神经元”**。你可以把它想象成大脑内部的一面“镜子”，能映射出别人的行为。
			- 当时科学家们猜想：这个机制可能帮助我们理解别人的意图、学习模仿，甚至可能是语言和同理心的基础。
		- ### **第二部分：被推上“神坛”**
		  collapsed:: true
			- 这个发现起初并没引起太大轰动。但十年后，一位非常有影响力的科学家——**拉马钱德兰**——把它推向了聚光灯下。
			- 他做了一个非常大胆的预言：**“镜像神经元对于心理学的意义，将如同DNA对于生物学的意义一样重大。”**
			- 他认为，镜像神经元可以解释很多人类独有的高级能力：
				- **模仿与学习**：为什么人类能迅速学会使用工具、掌握技能？因为我们有镜像神经元，能通过看就会。
				- **同理心（共情）**：为什么我们看到别人伤心，自己也会感到难过？因为镜像神经元让我们在脑中“模拟”了对方的情绪。
				- **理解他人**：为什么我们能“读心”，即理解别人的意图？因为我们能通过镜像神经元，在内心重演别人的行为。
				- **解释自闭症**：他甚至推测，自闭症患者的社交困难，可能就是因为他们大脑中的这面“镜子”坏掉了。
			- 一时间，镜像神经元成了“万能钥匙”，似乎能解释所有人类社交和认知的奥秘。从艺术鉴赏到国际外交，到处都在谈论它。它从一个小小的科学发现，变成了一个流行文化符号。
		- ### **第三部分：质疑与“跌落神坛”**
		  collapsed:: true
			- 然而，科学界有很多人开始觉得不对劲了。这股热潮把镜像神经元捧得太高了，很多说法缺乏扎实的证据。于是，反对的声音出现了，领军人物是科学家**希科克**。
			- 他和其他质疑者提出了几个关键问题：
				- **“相关”不等于“因果”**：大脑某个区域在“看”的时候活跃，不代表它就是“理解”这个行为的原因。就像你家的电表在你看电视时转得飞快，但你不能说电表就是生产电视节目的机器。
				- **人类的直接证据很少**：在猴子大脑里直接测到了单个镜像神经元，但在人类大脑中，绝大部分证据都来自脑成像（如fMRI），这些技术只能看到大脑区域的大致活动，无法精确到单个细胞。我们无法确定人脑里是否有和猴子一模一样的镜像神经元。
				- **反例的存在**：
					- 有些中风患者，大脑运动区受损，自己无法做某个动作（比如刷牙），但他们**完全能理解**别人刷牙的动作。如果镜像神经元是“理解”的必要条件，他们应该无法理解才对。
					- 猴子虽然有镜像神经元，但它们的模仿能力远不如人类。这说明单靠镜像神经元，无法解释人类强大的模仿学习能力。
					- 希科克等人认为，理解他人是一个更复杂的过程，需要大脑多个区域（如视觉、感觉、决策区域）协同工作，而不能把所有功劳都归给运动区的几个“镜像”细胞。
					- 由于这些猛烈的批评，科学界开始“避嫌”，研究人员担心提“镜像神经元”会被认为不严谨。相关的研究论文数量大幅下降，镜像神经元从科学的“神坛”上跌落了下来。
		- ### **第四部分：潮水退去，回归平凡与重要**
		  collapsed:: true
			- 当狂热退去，迷雾散开，科学家们现在对镜像神经元有了更冷静、更成熟的认识：
				- **它很重要，但不是万能的**。大家都同意，镜像神经元系统在我们**学习和模仿动作**方面扮演了重要角色。但它可能不是产生同理心或理解他人意图的**唯一**基础。
				- **定义被拓宽了**。科学家在大脑的其他区域，也发现了具有“镜像”特性的细胞。比如：
					- 看到别人恶心，你自己也感到恶心的脑区会激活。
					- 看到别人被触摸，你自己躯体感觉被触摸的脑区会激活。
					- 看到别人疼痛，你自己感知疼痛的脑区会激活。
					- 这说明，“镜像”可能是一种遍布大脑的、更普遍的原理，用于帮助我们快速理解和感受他人的**动作、感觉和情绪**。
		- ### 用一个比喻来总结整个故事
		  collapsed:: true
			- 镜像神经元就像一把新发现的、非常锋利的 **“瑞士军刀”**。
				- **最初**，发现者说：“看，这把刀能切东西！”
				- **然后**，追捧者过度兴奋地宣传：“这把刀是万能的！它能开罐头、拧螺丝、剪树枝，甚至能当主厨刀做出满汉全席！”（把它神化）
				- **接着**，批评者站出来说：“别胡说了！它拧螺丝不如专业螺丝刀，做菜更不如专业厨刀。你们夸大了它的功能。”（将它拉下神坛）
				- **最后**，大家冷静下来，达成共识：“这确实是一把非常有用且设计巧妙的工具，在野外应急时能解决很多问题。但它只是我们工具库中的一员，不能替代所有专业工具。”（回归其真实价值）
			- 所以，镜像神经元并没有消失，它只是从一个被过度炒作的神奇概念，回归到了一个**重要但平凡**的科学研究对象。它依然是我们理解大脑如何与社会互动的一块关键拼图，只是不再是唯一的那一块。这个故事也告诉我们，科学正是在这样的追捧、质疑和修正中，不断前进的。
- ## [[Books]]
  collapsed:: true
	- DONE 色戒
	- LATER 红楼梦
	  :LOGBOOK:
	  CLOCK: [2025-11-04 Tue 20:27:10]--[2025-11-04 Tue 20:27:12] =>  00:00:02
	  CLOCK: [2025-11-04 Tue 20:27:19]--[2025-11-05 Wed 15:01:52] =>  18:34:33
	  :END:
	- LATER 倾城之恋
	  :LOGBOOK:
	  CLOCK: [2025-11-04 Tue 20:27:21]--[2025-11-05 Wed 15:01:54] =>  18:34:33
	  :END:
		- DONE 沉香屑·第一炉香
	- LATER 爱的艺术
	  :LOGBOOK:
	  CLOCK: [2025-11-04 Tue 20:27:48]--[2025-11-05 Wed 15:01:57] =>  18:34:09
	  :END:
	- LATER 悉达多
	  :LOGBOOK:
	  CLOCK: [2025-11-04 Tue 20:47:06]--[2025-11-05 Wed 15:01:57] =>  18:14:51
	  :END:
- ## [[Movies]]
  collapsed:: true
	- [[baobao]]
		- DONE 蓝色大门
		- DONE 不能说的秘密
		- DONE 仙境之桥
		- LATER 哪吒闹海
		- DONE 色戒
		- LATER 爱死机
		  :LOGBOOK:
		  CLOCK: [2025-11-04 Tue 20:30:27]--[2025-11-05 Wed 15:01:58] =>  18:31:31
		  :END:
	- [[qinqin]]
		- DONE 哪吒1
		- DONE 哪吒2
		- DONE 机器人总动员
		- LATER 游园惊梦
		- DONE 爱乐之城
		- DONE 穆赫兰道
	- [[粤语经典]]
		- DONE 春光乍泄
		- DONE 阿飞正传
		- DONE 花样年华
		- LATER 霸王别姬
	- [[英文经典]]
		- LATER 海上钢琴师
		- LATER 闻香识女人
		- LATER 小妇人
		- LATER 乱世佳人
		- LATER 悲惨世界
		- LATER 时间旅行者的妻子
		- LATER 时空恋旅人
		- LATER 恋恋笔记本
		- LATER 爱在黎明破晓前
		- LATER 海边的曼彻斯特
	- [[中文经典]]
		- LATER 卧虎藏龙
		- LATER 大红灯笼高高挂
		- LATER 红高粱
	-